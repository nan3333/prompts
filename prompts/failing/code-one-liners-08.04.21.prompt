# This outputs multiple one-liners to save money / make it faster

title: "code one liners from natural language"
future-titles:
- "Get code snippet"
# Any language
- "Get snippet"
next-version: "get-code-snippet.prompt"
prompt-version: 3
doc: "Get a one liner from natural langauge"
prompt: |+
    One liners in various languages.

    Language: Clojure
    ###
    ;; map string/split
    ;; 4 examples:
    (map first (split-at 3 "Hello World"))
    (map #(str/split % #"\s+") ["a-b-c" "1-2-3"])
    (map #(str % #" ") ["Hello" "World"])
    (map #(apply str (reverse %)) (re-seq #"[^ ]+" "hi there"))
    ###
    Language: Ruby
    ###
    # extract values of a map to a list
    # 3 examples:
    hash.values
    hash.map { |key, value| value }
    hash.collect { |k, v| v }
    ###
    Language: haskell
    ###
    -- multiply each item in a list by 2
    map (*2) [1..10]
    map (*2) [1..5]
    ###
    Language: <1>
    ###
    -- <2>
    -- 10 examples:
    <:pp>-
engine: "davinci"
# 0.0 = /r/ihadastroke
# 1.0 = /r/iamveryrandom
# Use 0.3-0.8
temperature: 0.8
max-tokens: 60
top-p: 1.0
# Not available yet: openai api completions.create --help
frequency-penalty: 0.5
# If I make presence-penalty 0 then it will get very terse
presence-penalty: 0.0
best-of: 1
stop-sequences:
# - "\n"
# - "\n\n"
- "###"
inject-start-text: yes
inject-restart-text: yes
show-probabilities: off
vars:
- "language"
- "task"
examples:
- "bash"
- "suspend laptop"
chomp-start: on
chomp-end: off
external: ""
conversation-mode: no
filter: no
# Keep stitching together until reaching this limit
# This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
stitch-max: 0
needs-work: no
postprocessor: "sed '/^- /s/- //p' | sed '/^-/d' | uniqnosort"